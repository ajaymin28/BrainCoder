# ğŸ§  BrainCoder

**BrainCoder** is a research project focused on decoding visual stimuli from EEG (Electroencephalogram) signals.  
The goal is to **learn generalized features** from brain activity that can accurately predict image representations across different subjects, enabling cross-subject decoding.

This project explores how to align EEG signals with powerful visual-semantic embeddings like [CLIP](https://openai.com/research/clip).

---

## ğŸ“š Project Overview

- **Problem:** EEG signals are noisy and highly subject-specific, making cross-subject generalization challenging.
- **Solution:** Train models that map EEG signals to the corresponding **CLIP image features** while minimizing subject-specific variance.
- **Key idea:**  
  - Learn **subject-invariant** EEG representations.
  - Align EEG encodings with **vision-language embeddings**.
  
---

## ğŸ› ï¸ Code Structure

```
BrainCoder/
â”œâ”€â”€ configs/         # YAML config files for experiments
â”œâ”€â”€ dataset/         # EEG Dataset processing and loading
â”œâ”€â”€ archs/           # model archs to use
â”œâ”€â”€ metrics/         # Evaluation metrics
â”œâ”€â”€ models/          # EEG encoders, CLIP-based models
â”œâ”€â”€ utils/           # Utility functions (logging, checkpointing)
â”œâ”€â”€ train.py         # Entry point for training
â”œâ”€â”€ eval.py          # Entry point for evaluation
â”œâ”€â”€ requirements.txt # Required Python packages
â””â”€â”€ README.md        # (You're reading it!)
```


---

## ğŸ§  Dataset

- EEG recordings collected while subjects viewed images.
- Each EEG signal is paired with the corresponding **CLIP image embedding**.
- Preprocessing steps: filtering, segmentation, normalization.

(*Dataset loading scripts are available in the `dataset/` folder.*)

---

## âœ¨ Features

- Flexible EEG encoder architectures.
- Subject-invariant training (domain adversarial techniques planned).
- Contrastive learning between EEG features and image embeddings.
- Modular and easily extensible codebase.

---

## ğŸ“ˆ TODOs
- [ ] Update readme.md
- [ ] Add domain adversarial training to improve cross-subject generalization.
- [ ] Extend to zero-shot classification using CLIP text embeddings.
- [ ] Improve visualization of EEG feature space (e.g., t-SNE plots).
- [ ] Add pretrained model checkpoints.

---

## ğŸ¤ Contributing

Contributions, ideas, and discussions are welcome!  
Feel free to open an issue or submit a pull request.

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ™Œ Acknowledgements

- [OpenAI CLIP](https://github.com/openai/CLIP) for image embeddings.
- Inspiration from research on EEG-to-vision-language alignment.